#!/usr/bin/env python3

import os
import sys
import argparse
from dotenv import load_dotenv
import asyncio

from autogen_core.models import UserMessage, SystemMessage

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from utils import find_dotenv_file
from utils.assistant_auth import PEAKAssistantAuthManager
from utils.azure_client import PEAKAssistantAzureOpenAIClient


async def able_table(
    hypothesis: str,
    research_document: str,
    local_context: str,
    previous_run: list = list(),
) -> str:
    """
    Generate a PEAK ABLE table based on the given hypothesis and research document.

    Args:
        hypothesis (str): The threat hunting hypothesis.
        research_document (str): The research document containging info about the
            behavior or technique being hunted for.

    Returns:
        str: The output generated by the LLM.
    """
    # Define the system prompt for the hypothesizer
    system_prompt = """
        You are an expert in cybersecurity threat hunting, especially the PEAK
        Threat Hunting Framework. 

        Even when you have a clear and testable hypothesis, you still need to know a few
        things before you can start hunting. You need to know possible indicators of the
        activity, data source(s) you need to examine, and which parts of the network the
        activity is happening in. 

        PEAK incorporates the ABLE method to help you capture the critical pieces of
        your hunting hypothesis, which include:

            - Actor: The threat actor (or sometimes the general type of threat actor) that you are
                looking for. Many behaviors are not tied to a specific actor, so you won’t always
                need to specify this part. But if you do, it can supply valuable context to help
                with the rest of your hunt.
            - Behavior: The specific activity you’re trying to find — sometimes called TTPs (Tactics,
                Techniques, and Procedures). Instead of hunting for an entire attack lifecycle’s
                worth of behavior, focus on one or two pieces at a time.
            - Location: The part(s) of your organization’s network where you would expect to find the
                behavior (e.g., “end-user desktops,” “internet-facing web servers,” or even just
                “internal” versus “perimeter”). A proper location helps narrow the scope of your
                hunt, making it easier and more efficient.
            - Evidence: A combination of which data source(s) you’d need to consult to find the activity
                and what it would look like if it were present. You’ll need to know these when you
                plan your data collection and create your analysis strategy.

        Example: Using ABLE to hunt DNS exfiltration

        Consider the following hypothesis: “PIFFLING PANGOLIN may be exfiltrating
        sensitive financial data using DNS tunneling.” Here’s how you might break this
        down using the ABLE framework.
    
        Actor: Although financial data would appeal to many cybercriminals, this
        hypothesis is about a specific group. Understanding this actor’s typical
        operations may give you clues to aid in your hunt, such as known C2 domains
        or specific tools they use for DNS tunnels.
    
        Behavior: The behavior you’re hunting for is data exfiltration through DNS
        tunneling. By focusing on this specific tactic, you can narrow down your
        investigation and concentrate on relevant indicators of compromise.
    
        Location: The hypothesis suggests that the finance department is being
        targeted. This pinpoints the parts of the network that you need to scrutinize —
        the finance network for the source of the data and the network perimeter for
        the internet-based exfiltration.
    
        Evidence: To detect DNS tunneling, examine DNS query logs or full passive
        DNS logs. Look for unusually large or frequent DNS queries, odd DNS query
        types or indicators of known DNS tunneling tools.
    
        
        As the ABLE agent, your task is to read the user's hunting hypothesis as
        well as the research document and generate a PEAK ABLE table. Take your time 
        and think carefully about the hypothesis and the research document in order
        to produce the best possible table. 

        The output should be a Markdown document with the following format:
            - Title: 1st level header with the title "PEAK ABLE Table: " followed by the 
                common name for the technique being hunted for.
            - Hypothesis: Italic text with the text "Hypothesis: " followed by the user's
                hunting hypothesis.
            - ABLE Table: An easy-to-read table with the following columns:
                - "ABLE Element": The name of the ABLE element (Actor, Behavior, Location, Evidence)
                - An untitled column with the content of the ABLE element   
            - Notes: If there are any notes or additional information that the user should
                be aware of, include them here. This should be a bulleted list. This is an 
                option section and should be omitted if there are no notes. 
    """

    messages = [
        SystemMessage(content=system_prompt),
        UserMessage(
            content=f"Here is the research document:\n{research_document}\n",
            source="user",
        ),
        UserMessage(
            content=f"Here is the user's hunting hypothesis: {hypothesis}\n",
            source="user",
        ),
        UserMessage(
            content=f"Additional local context: {local_context}\n", source="user"
        ),
    ]

    # If we have messages from a previous run, add them so we can continue the research
    if previous_run:
        messages = messages + previous_run

    auth_mgr = PEAKAssistantAuthManager()
    az_model_client = await PEAKAssistantAzureOpenAIClient().get_client(
        auth_mgr=auth_mgr
    )

    # Call the LLM using the AzureOpenAIChatCompletionClient
    try:
        result = await az_model_client.create(messages)  # Await the async method
        # Access the content from the CreateResult object
        return (
            result.content
        )  # Use the correct attribute to access the generated content
    except Exception as e:
        print(f"Error while generating hypotheses: {e}")
        return "An error occurred while generating hypotheses."


# Example usage
if __name__ == "__main__":
    # Set up argument parser
    parser = argparse.ArgumentParser(
        description="Given a threat hunting technique dossier, generate potential hypotheses for the hunter."
    )
    parser.add_argument("-e", "--environment", help="Path to specific .env file to use")
    parser.add_argument(
        "-r",
        "--research",
        help="Path to the research document (markdown file)",
        required=True,
    )
    parser.add_argument(
        "-y", "--hypothesis", help="The hunting hypothesis", required=True, default=""
    )
    parser.add_argument(
        "-c",
        "--local_context",
        help="Additional local context to consider",
        required=False,
        default=None,
    )
    args = parser.parse_args()

    # Load environment variables
    if args.environment:
        # Use the specified .env file
        dotenv_path = args.environment
        if not os.path.exists(dotenv_path):
            print(f"Error: Specified environment file '{dotenv_path}' not found")
            exit(1)
        load_dotenv(dotenv_path)
    else:
        # Search for .env file
        dotenv_path = find_dotenv_file()
        if dotenv_path:
            load_dotenv(dotenv_path)
        else:
            print("Warning: No .env file found in current or parent directories")

    # Read the contents of the research document
    try:
        with open(args.research, "r", encoding="utf-8") as file:
            research_data = file.read()
    except FileNotFoundError:
        print(f"Error: Research document '{args.research}' not found")
        exit(1)
    except Exception as e:
        print(f"Error reading research document: {e}")
        exit(1)

    # Read the contents of the local context if provided
    local_context = None
    if args.local_context:
        try:
            with open(args.local_context, "r", encoding="utf-8") as file:
                local_context = file.read()
        except FileNotFoundError:
            print(f"Error: Local context file '{args.local_context}' not found")
            exit(1)
        except Exception as e:
            print(f"Error reading local context: {e}")
            exit(1)

    messages = list()
    while True:
        # Run the hypothesizer asynchronously
        able = asyncio.run(
            able_table(
                hypothesis=args.hypothesis,
                research_document=research_data,
                local_context=local_context,
                previous_run=messages,
            )
        )
        print(able)

        feedback = input(
            "Please provide your feedback on the ABLE table (or press Enter to approve it): "
        )

        if feedback.strip():
            # If feedback is provided, add it to the messages and loop back to
            # the research team for further refinement
            messages = [
                UserMessage(
                    content=f"The current ABLE draft is: {able}\n", source="user"
                ),
                UserMessage(content=f"User feedback: {feedback}\n", source="user"),
            ]
        else:
            break
