#!/usr/bin/env python3

import os
import sys
import argparse
from dotenv import load_dotenv
import asyncio

from autogen_agentchat.messages import TextMessage
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_agentchat.ui import Console
from autogen_agentchat.conditions import TextMentionTermination

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from utils import find_dotenv_file
from utils.assistant_auth import PEAKAssistantAuthManager
from utils.azure_client import PEAKAssistantAzureOpenAIClient
from utils.mcp_config import get_client_manager, setup_mcp_servers


async def identify_data_sources(
    hypothesis: str = None,
    research_document: str = None,
    able_info: str = None,
    local_context: str = None,
    verbose: bool = False,
    previous_run: list = None,
    mcp_server_group: str = "data_discovery",
) -> str:
    """
    Data agent that consumes a hunting research report and a hypothesis, then
    queries the Splunk server to try to identify data sources that could be used
    to test the hypothesis.

    Args:
        hypothesis (str): A string containing the hypothesis to be tested.
        research_document (str): A longer string containing a complete markdown document.

    Returns:
        str: The output generated by the LLM.
    """
    # Define the system prompt for the hypothesizer
    data_discovery_prompt = """
        You are an expert in cybersecurity threat hunting. As the data discovery agent,
        your task is examine the provided hypothesis and the threat hunting behavior or 
        technique research document, then identify potential Splunk indices or data sources 
        that could be used to test the hypothesis from my actual Splunk server.

        Keep in mind the following guidelines:
        - Carefully analyze the hypothesis to understand its context and requirements.
        - Extract relevant information from the research document.
        - Combine both to identify specific Splunk indices or data sources that would be useful
          for testing the hypothesis. 
        - You must actually inspect the events in every index and their fields in Splunk to ensure they
          contain relevant data.
        - The actual index or field names in Splunk may not match the names in the research document. 
          You may need to inspect data in Splunk to find the correct names.
        - If the exact type of data you expect is not availalble, it is possible that there is a
          similar type of data that could be used instead.
        - Do not report indices, sourcetypes or fields that are not relevant. For example,
          it is not necessary to report indices that contain data that is not relevant or
          that contain no data at all. Only report data sources that might be helpful 
          to the hunter.

        Respond with a list of potential Splunk indices or data sources, a brief description of the type
        of data they contain (high level, such as "Windows Event Logs" or "Linux authentication events" is OK)
        as well as a description of the key fields, or the the fields most likely to contain the 
        data needed to test the hypothesis. All of this should be in markdown table format, 
        though you may include brief notes in markdown format if necessary.

        Only present your conclusions in the response, do not include any other text. Do not offer
        to provide more information or suggest additional tasks.
        
        When receiving feedback from a verifier agent, use your tools to iteratively refine
        your understanding of the data sources and fields and their relevance to the 
        hypothesis. 

        If you cannot identify an appropriate data source, please respond with "No suitable data sources found."
        followed by a brief explanation of why no data sources were identified and the closest data source(s) 
        you could find.
    """

    discovery_critic_prompt = """
        You are an expert in cybersecurity threat hunting. As the data discovery critic agent,
        your task is to review the output of the data discovery agent and provide feedback on the
        identified Splunk indices or data sources. You must ensure that the identified data
        sources are relevant to the hypothesis and the research document. Don't hesitate to
        ask the data discovery agent to refine its understanding of the data sources
        and fields and their relevance to the hypothesis if necessary.

        Remember to be on the lookout for the following:
        - Ensure that the identified data sources are relevant to the hypothesis and the research document.
        - If the data discovery agent has not identified all the relevant data sources and fields,
          provide constructive feedback to help it refine its understanding.
        - If the data discovery agent has identified some relevant data sources but not all,
          ask it to iterate and explore further.
        - Ensure that the data discovery agent is not making assumptions about the data 
          source contents based on the research document alone. It must actually inspect 
          the data in Splunk. Random samples are usually good enough to determine
          whether the data source is relevant or not.

        If you believe the data discovery agent has identified all the relevant data sources and fields,
        respond with "YYY-TERMINATE-YYY" to indicate that the data discovery agent can stop iterating.
    """

    messages = [
        TextMessage(
            content=f"Here is the research document:\n{research_document}\n",
            source="user",
        ),
        TextMessage(content=f"Here is the hypothesis: {hypothesis}\n", source="user"),
        TextMessage(
            content=f"The Actor, Behavior, Location and Evidence (ABLE) information is as follows: {able_info}",
            source="user",
        ),
        TextMessage(
            content=f"Additional local context: {local_context}\n", source="user"
        ),
    ]

    # If we have messages from a previous run, add them so we can continue the research
    if previous_run:
        messages = messages + previous_run

    # Initialize the model client
    auth_mgr = PEAKAssistantAuthManager()
    az_model_client = await PEAKAssistantAzureOpenAIClient().get_client(
        auth_mgr=auth_mgr
    )
    az_model_reasoning_client = await PEAKAssistantAzureOpenAIClient().get_client(
        auth_mgr=auth_mgr, model_type="reasoning"
    )

    # Set up MCP servers for data discovery
    mcp_client_manager = get_client_manager()
    connected_servers = await setup_mcp_servers(mcp_server_group)

    if not connected_servers:
        error_msg = f"No MCP servers could be connected from group '{mcp_server_group}'. Check your MCP configuration."
        if verbose:
            print(error_msg)
        raise RuntimeError(error_msg)

    if verbose:
        print(
            f"Connected to {len(connected_servers)} MCP servers for data discovery: {', '.join(connected_servers)}"
        )

    # Get workbenches only from the data discovery server group
    group_workbenches = []
    for server_name in connected_servers:
        workbench = mcp_client_manager.get_workbench(server_name)
        if workbench:
            group_workbenches.append(workbench)

    if not group_workbenches:
        error_msg = f"No MCP workbenches available for data discovery group '{mcp_server_group}'. Check your MCP configuration."
        if verbose:
            print(error_msg)
        raise RuntimeError(error_msg)

    # Use the first workbench from the data discovery group
    mcp_workbench = group_workbenches[0]
    return await _run_data_discovery_with_workbench(
        mcp_workbench,
        messages,
        data_discovery_prompt,
        discovery_critic_prompt,
        az_model_client,
        az_model_reasoning_client,
        verbose,
        previous_run,
    )


async def _run_data_discovery_with_workbench(
    mcp_workbench,
    messages,
    data_discovery_prompt,
    discovery_critic_prompt,
    az_model_client,
    az_model_reasoning_client,
    verbose,
    previous_run,
):
    """Helper function to run data discovery with a given MCP workbench"""

    data_discovery_agent = AssistantAgent(
        "Data_Discovery_Agent",
        model_client=az_model_client,
        workbench=mcp_workbench,
        reflect_on_tool_use=True,
        model_client_stream=True,
        system_message=data_discovery_prompt,
    )

    discovery_critic_agent = AssistantAgent(
        "Discovery_Critic_Agent",
        model_client=az_model_reasoning_client,
        system_message=discovery_critic_prompt,
    )

    # Define a termination condition that stops the task once the summarizer
    # agent has completed its task
    text_termination = TextMentionTermination("YYY-TERMINATE-YYY")

    team = RoundRobinGroupChat(
        participants=[data_discovery_agent, discovery_critic_agent],
        termination_condition=text_termination,
    )

    try:
        if verbose:
            result = await Console(team.run_stream(task=messages))
        else:
            result = await team.run(task=messages)
        return result
    except Exception as e:
        print(f"Error during data source identification: {e}")
        return f"An error occurred during data source identification: {e}"


# Example usage
if __name__ == "__main__":
    # Set up argument parser
    parser = argparse.ArgumentParser(
        description="Given a threat hunting technique dossier and a hypothesis, determine what relevant data is present on the Splunk server."
    )
    parser.add_argument("-e", "--environment", help="Path to specific .env file to use")
    parser.add_argument(
        "-r",
        "--research",
        help="Path to the research document (markdown file)",
        required=True,
    )
    parser.add_argument(
        "-y", "--hypothesis", help="The hunting hypothesis", required=True
    )
    parser.add_argument(
        "-a",
        "--able_info",
        help="The Actor, Behavior, Location and Evidence (ABLE) information",
        required=False,
        default=None,
    )
    parser.add_argument(
        "-c",
        "--local_context",
        help="Additional local context to consider",
        required=False,
        default=None,
    )
    parser.add_argument(
        "-v",
        "--verbose",
        action="store_true",
        help="Enable verbose output",
        default=False,
    )
    args = parser.parse_args()

    # Load environment variables
    if args.environment:
        # Use the specified .env file
        dotenv_path = args.environment
        if not os.path.exists(dotenv_path):
            print(f"Error: Specified environment file '{dotenv_path}' not found")
            exit(1)
        load_dotenv(dotenv_path)
    else:
        # Search for .env file
        dotenv_path = find_dotenv_file()
        if dotenv_path:
            load_dotenv(dotenv_path)
        else:
            print("Warning: No .env file found in current or parent directories")

    # Read the contents of the research document
    try:
        with open(args.research, "r", encoding="utf-8") as file:
            research_data = file.read()
    except FileNotFoundError:
        print(f"Error: Research document '{args.research}' not found")
        exit(1)
    except Exception as e:
        print(f"Error reading research document: {e}")
        exit(1)

    # Read the contents of the ABLE information if provided
    able_info = None
    if args.able_info:
        try:
            with open(args.able_info, "r", encoding="utf-8") as file:
                able_info = file.read()
        except FileNotFoundError:
            print(f"Error: ABLE information file '{args.able_info}' not found")
            exit(1)
        except Exception as e:
            print(f"Error reading ABLE information: {e}")
            exit(1)

    # Read the contents of the local context if provided
    local_context = None
    if args.local_context:
        try:
            with open(args.local_context, "r", encoding="utf-8") as file:
                local_context = file.read()
        except FileNotFoundError:
            print(f"Error: Local context file '{args.local_context}' not found")
            exit(1)
        except Exception as e:
            print(f"Error reading local context: {e}")
            exit(1)

    messages = list()
    while True:
        # Run the hypothesizer asynchronously
        data_sources = asyncio.run(
            identify_data_sources(
                hypothesis=args.hypothesis,
                research_document=research_data,
                able_info=able_info,
                local_context=local_context,
                verbose=args.verbose,
                previous_run=messages,
            )
        )

        # Find the final message from the "critic" agent using next() and a generator expression
        data_sources_message = next(
            (
                message.content
                for message in reversed(data_sources.messages)
                if message.source == "Data_Discovery_Agent"
            ),
            None,  # Default value if no "critic" message is found
        )

        # Display the data sources and ask for user feedback
        print(data_sources_message)
        feedback = input(
            "Please provide your feedback on the data sources (or press Enter to approve it): "
        )

        if feedback.strip():
            # If feedback is provided, add it to the messages and loop back to
            # the data discovery team for further refinement
            messages = [
                TextMessage(
                    content=f"The current data sources draft is: {data_sources_message}\n",
                    source="user",
                ),
                TextMessage(content=f"User feedback: {feedback}\n", source="user"),
            ]
        else:
            break
