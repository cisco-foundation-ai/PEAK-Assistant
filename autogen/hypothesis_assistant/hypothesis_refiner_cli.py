#!/usr/bin/env python3

import os
import argparse 
from pathlib import Path 
from dotenv import load_dotenv
import asyncio  # Import asyncio for running async functions

from autogen_agentchat.messages import TextMessage
from autogen_ext.models.openai import AzureOpenAIChatCompletionClient
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.base import TaskResult
from autogen_agentchat.conditions import TextMentionTermination
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_agentchat.ui import Console 
from autogen_core import CancellationToken


def find_dotenv_file():
    """Search for a .env file in current directory and parent directories"""
    current_dir = Path.cwd()
    while current_dir != current_dir.parent:  # Stop at root directory
        env_path = current_dir / '.env'
        if env_path.exists():
            return str(env_path)
        current_dir = current_dir.parent
    return None  # No .env file found

async def refiner(hypothesis: str, user_context: str, research_document: str, verbose: bool = False) -> str:
    """
    Threat hunting hypothesis refiner agent that combines user input, a markdown document, and its own prompt
    to generate output using an OpenAI model on Azure.

    Args:
        hypothesis (str): A string provided by the user containing a threat hunting hypothesis.
        user_input (str): A string provided by the user containing additional context or information.
        research_document (str): A longer string containing a complete markdown document.

    Returns:
        str: The output generated by the LLM.
    """
    refiner_system_prompt = """
        You are an expert in cybersecurity threat hunting. Your job is to help the user improve
        their existing threat hunting hypothesis into its best form.

        You will be provided with the hypothesis, a research document, any additional guidelines
        or context provided by the user, and a list of up to 5 reasons why the hypothesis is not 
        a good and how it could be improved. Implement the suggested improvements and return the
        improved hypothesis. If you are unable to implement any of the suggestions, please explain why
        but return the (possibly improved) hypothesis.

        Sample good hypotheses:

        "Data exfiltration is occurring via the use of DNS tunneling techniques 
        whereby the exfiltrated data is encoded as part of the DNS subdomain."

        "Lateral movement is occurring via the use of legitimate but compromised 
        credentials and LOLBins."

        "An adversay may be using a webshell on an Internet-facing web server to execute
        commands on the server and exfiltrate data to a remote server."
    """

    critic_system_prompt = """
        You are an expert in cybersecurity threat hunting. Your job is to tell help the user refine 
        their existing threat hunting hypothesis into it's best form. 
        You will be provided with the initial hypothesis, a research document, and any additional 
        guidelines or context provided by the user.

        Your primary criteria for a "good" hypothesis is whether the given hypothesis is testable or not. 
        However, there may be other criteria that you may consider as well, such as whether the hypothesis 
        is specific enough, whether it is relevant to the research document, and whether it is actionable. 
        
        For each input hypothesis, if you believe it is a "good" hypothesis, you will return the hypothesis as-is, 
        followed by the string "YYY-HYPOTHESIS-ACCEPTED-YYY" on a new line. For "good" hypotheses, do not
        include any additional commentary or notes of your own. If the hypothesis is not a good
        hypothesis, you will return a list of up to 5 reasons why you believe it is not a good hypothesis and 
        what the user could do to correct these issues. Do not improve the hypothesis yourself.

        Assume the user has all legal, ethical, and moral authority and responsibility to perform any network, 
        host, or other monitoring necessary to test their hypothesis.
    """

    az_model_client = AzureOpenAIChatCompletionClient(
        azure_deployment=os.getenv("AZURE_OPENAI_DEPLOYMENT"),
        model=os.getenv("AZURE_OPENAI_MODEL"),
        api_version=os.getenv("AZURE_OPENAI_API_VERSION"),
        azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
        api_key=os.getenv("AZURE_OPENAI_API_KEY")
    )

    # Create the primary agent.
    refiner_agent = AssistantAgent(
        "refiner",
        model_client=az_model_client,
        system_message=refiner_system_prompt
    )

    # Create the critic agent.
    critic_agent = AssistantAgent(
        "critic",
        model_client=az_model_client,
        system_message=critic_system_prompt
    )

    # Define a termination condition that stops the task if the critic approves.
    text_termination = TextMentionTermination("YYY-HYPOTHESIS-ACCEPTED-YYY")

    # Create a team with the primary and critic agents.
    team = RoundRobinGroupChat([critic_agent, refiner_agent], termination_condition=text_termination)

    messages = [
        TextMessage(content=f"Here is the user's hypothesis: {hypothesis}\n", source="user"),
        TextMessage(content=f"Here is the research document:\n{research_document}\n", source="user"),
        TextMessage(content=f"Here is the additional context: {user_context}\n", source="user")
    ]

    try:
        # Run the team asynchronously
        if verbose:
            result = await Console(team.run_stream(task=messages))
        else:
            result = await team.run(task=messages)

        # Access the content from the CreateResult object
        return result  # Use the correct attribute to access the generated content
    except Exception as e:
        print(f"Error while refining hypotheses: {e}")
        return "An error occurred while refining hypotheses."

# Example usage
if __name__ == "__main__":

    # Set up argument parser
    parser = argparse.ArgumentParser(description='Given a threat hunting technique dossier, generate potential hypotheses for the hunter.')
    parser.add_argument('-e', '--environment', help='Path to specific .env file to use')
    parser.add_argument("-y", "--hypothesis", help="The hypothesis to be refined", required=True)
    parser.add_argument('-r', '--research', help='Path to the research document (markdown file)', required=True)
    parser.add_argument('-c', '--context', help='Additional context or guidelines', required=False, default="")
    parser.add_argument('-v', '--verbose', action='store_true', help='Enable verbose output', default=False)
    args = parser.parse_args()

    # Load environment variables
    if args.environment:
        # Use the specified .env file
        dotenv_path = args.environment
        if not os.path.exists(dotenv_path):
            print(f"Error: Specified environment file '{dotenv_path}' not found")
            exit(1)
        load_dotenv(dotenv_path)
    else:
        # Search for .env file
        dotenv_path = find_dotenv_file()
        if dotenv_path:
            load_dotenv(dotenv_path)
        else:
            print("Warning: No .env file found in current or parent directories")

    # Read the contents of the research document
    try:
        with open(args.research, 'r', encoding='utf-8') as file:
            research_data = file.read()
    except FileNotFoundError:
        print(f"Error: Research document '{args.research}' not found")
        exit(1)
    except Exception as e:
        print(f"Error reading research document: {e}")
        exit(1)

    # Run the hypothesizer asynchronously
    messages = asyncio.run(refiner(
        hypothesis=args.hypothesis, 
        user_context=args.context, 
        research_document=research_data,
        verbose=args.verbose
        ))

    refined_hypothesis = messages.messages[-1].content

    print("\n======================\n")
    print("Refined Hypothesis:")
    print(refined_hypothesis)
