#!/usr/bin/env python3

import os
import sys
import argparse
from dotenv import load_dotenv
import asyncio

from autogen_agentchat.messages import TextMessage
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.conditions import TextMentionTermination
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_agentchat.ui import Console

sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))
from utils import find_dotenv_file
from utils.assistant_auth import PEAKAssistantAuthManager
from utils.azure_client import PEAKAssistantAzureOpenAIClient


async def refiner(
    hypothesis: str,
    local_context: str,
    research_document: str,
    verbose: bool = False,
    previous_run: list = list(),
) -> str:
    """
    Threat hunting hypothesis refiner agent that combines user input, a markdown document, and its own prompt
    to generate output using an OpenAI model on Azure.

    Args:
        hypothesis (str): A string provided by the user containing a threat hunting hypothesis.
        user_input (str): A string provided by the user containing additional context or information.
        research_document (str): A longer string containing a complete markdown document.

    Returns:
        str: The output generated by the LLM.
    """
    refiner_system_prompt = """
        You are an expert in cybersecurity threat hunting. Your job is to help the user improve
        their existing threat hunting hypothesis into its best form.

        You will be provided with the hypothesis, a research document, any additional guidelines
        or context provided by the user, and a list of up to 5 reasons why the hypothesis is not 
        a good and how it could be improved. Implement the suggested improvements and return the
        improved hypothesis. If you are unable to implement any of the suggestions, please explain why
        but return the (possibly improved) hypothesis.

        Sample good hypotheses:

        "Data exfiltration is occurring via the use of DNS tunneling techniques 
        whereby the exfiltrated data is encoded as part of the DNS subdomain."

        "Lateral movement is occurring via the use of legitimate but compromised 
        credentials and LOLBins."

        "An adversay may be using a webshell on an Internet-facing web server to execute
        commands on the server and exfiltrate data to a remote server."
    """

    critic_system_prompt = """
        You are an expert in cybersecurity threat hunting. Your job is to tell help the user refine 
        their existing threat hunting hypothesis into it's best form. 
        You will be provided with the initial hypothesis, a research document, and any additional 
        guidelines or context provided by the user.

        Your primary criteria for a "good" hypothesis is whether the given hypothesis is testable or not. 
        However, there may be other criteria that you may consider as well, such as whether the hypothesis 
        is specific enough, whether it is relevant to the research document, and whether it is actionable. 
        
        For each input hypothesis, if you believe it is a "good" hypothesis, you will return the hypothesis as-is, 
        followed by the string "YYY-HYPOTHESIS-ACCEPTED-YYY" on a new line. For "good" hypotheses, do not
        include any additional commentary or notes of your own. If the hypothesis is not a good
        hypothesis, you will return a list of up to 5 reasons why you believe it is not a good hypothesis and 
        what the user could do to correct these issues. Do not improve the hypothesis yourself.

        Assume the user has all legal, ethical, and moral authority and responsibility to perform any network, 
        host, or other monitoring necessary to test their hypothesis.
    """

    auth_mgr = PEAKAssistantAuthManager()
    az_model_client = await PEAKAssistantAzureOpenAIClient().get_client(
        auth_mgr=auth_mgr
    )
    # _az_model_reasoning_client = await PEAKAssistantAzureOpenAIClient().get_client(
    #     auth_mgr=auth_mgr, model_type="reasoning"
    # )

    # Create the primary agent.
    refiner_agent = AssistantAgent(
        "refiner", model_client=az_model_client, system_message=refiner_system_prompt
    )

    # Create the critic agent.
    critic_agent = AssistantAgent(
        "critic", model_client=az_model_client, system_message=critic_system_prompt
    )

    # Define a termination condition that stops the task if the critic approves.
    text_termination = TextMentionTermination("YYY-HYPOTHESIS-ACCEPTED-YYY")

    # Create a team with the primary and critic agents.
    team = RoundRobinGroupChat(
        [critic_agent, refiner_agent], termination_condition=text_termination
    )

    # Always add these, no matter if it's the first run or a subsequent one
    messages = [
        TextMessage(
            content=f"Here is the user's hypothesis: {hypothesis}\n", source="user"
        ),
        TextMessage(
            content=f"Here is the research document:\n{research_document}\n",
            source="user",
        ),
        TextMessage(
            content=f"Additional local context: {local_context}\n", source="user"
        ),
    ]

    # If we have messages from a previous run, add them so we can continue the research
    if previous_run:
        messages = messages + previous_run

    try:
        # Run the team asynchronously
        if verbose:
            result = await Console(team.run_stream(task=messages), output_stats=True)
        else:
            result = await team.run(task=messages)

        # Access the content from the CreateResult object
        return result  # Use the correct attribute to access the generated content
    except Exception as e:
        print(f"Error while refining hypotheses: {e}")
        return "An error occurred while refining hypotheses."


# Example usage
if __name__ == "__main__":
    # Set up argument parser
    parser = argparse.ArgumentParser(
        description="Given a threat hunting technique dossier, generate potential hypotheses for the hunter."
    )
    parser.add_argument("-e", "--environment", help="Path to specific .env file to use")
    parser.add_argument(
        "-y", "--hypothesis", help="The hypothesis to be refined", required=True
    )
    parser.add_argument(
        "-r",
        "--research",
        help="Path to the research document (markdown file)",
        required=True,
    )
    parser.add_argument(
        "-c",
        "--local_context",
        help="Additional local context to consider",
        required=False,
        default=None,
    )
    parser.add_argument(
        "-v",
        "--verbose",
        action="store_true",
        help="Enable verbose output",
        default=False,
    )
    parser.add_argument(
        "-a",
        "--automated",
        action="store_true",
        help="Enable automated mode",
        default=False,
    )

    # Parse the arguments
    args = parser.parse_args()

    # Enforce verbose behavior based on the automated flag
    if not args.automated:
        # Force verbose to True if not in automated mode
        args.verbose = True

    # Load environment variables
    if args.environment:
        # Use the specified .env file
        dotenv_path = args.environment
        if not os.path.exists(dotenv_path):
            print(f"Error: Specified environment file '{dotenv_path}' not found")
            exit(1)
        load_dotenv(dotenv_path)
    else:
        # Search for .env file
        dotenv_path = find_dotenv_file()
        if dotenv_path:
            load_dotenv(dotenv_path)
        else:
            print("Warning: No .env file found in current or parent directories")

    # Read the contents of the research document
    try:
        with open(args.research, "r", encoding="utf-8") as file:
            research_data = file.read()
    except FileNotFoundError:
        print(f"Error: Research document '{args.research}' not found")
        exit(1)
    except Exception as e:
        print(f"Error reading research document: {e}")
        exit(1)

    # Read the contents of the local context if provided
    local_context = None
    if args.local_context:
        try:
            with open(args.local_context, "r", encoding="utf-8") as file:
                local_context = file.read()
        except FileNotFoundError:
            print(f"Error: Local context file '{args.local_context}' not found")
            exit(1)
        except Exception as e:
            print(f"Error reading local context: {e}")
            exit(1)

    messages = list()
    current_hypothesis = args.hypothesis
    while True:
        # Run the hypothesizer asynchronously
        messages = asyncio.run(
            refiner(
                hypothesis=current_hypothesis,
                local_context=local_context,
                research_document=research_data,
                verbose=args.verbose,
                previous_run=messages,
            )
        )

        # Find the final message from the "critic" agent using next() and a generator expression
        refined_hypothesis_message = next(
            (
                message.content
                for message in reversed(messages.messages)
                if message.source == "critic"
            ),
            None,  # Default value if no "critic" message is found
        )

        # Remove the trailing "YYY-HYPOTHESIS-ACCEPTED-YYY" string
        current_hypothesis = refined_hypothesis_message.replace(
            "YYY-HYPOTHESIS-ACCEPTED-YYY", ""
        ).strip()

        # Print the refined hypothesis and ask for user feedback
        print(current_hypothesis)
        feedback = input(
            "Please provide your feedback on the refined hypothesis (or press Enter to approve it): "
        )

        if feedback.strip():
            # If feedback is provided, add it to the messages and loop back to the refiner
            messages = [
                TextMessage(content=f"User feedback: {feedback}\n", source="user")
            ]
        else:
            break
