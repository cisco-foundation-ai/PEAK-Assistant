#!/usr/bin/env python3
# Copyright (c) 2025 Cisco Systems, Inc. and its affiliates
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
#
# SPDX-License-Identifier: MIT


import os
import argparse
from dotenv import load_dotenv
import asyncio

from autogen_core.models import UserMessage, SystemMessage

from ..utils import find_dotenv_file
from ..utils.llm_factory import get_model_client


async def hypothesizer(
    user_input: str, 
    research_document: str, 
    local_data_document: str,
    local_context: str
) -> str:
    """
    Hypothesizer agent that combines user input, a markdown document, and its own prompt
    to generate output using the configured LLM provider.

    Args:
        user_input (str): A string provided by the user.
        research_document (str): A longer string containing a complete markdown document.
        local_context (str): Additional context that may be relevant to the hypothesis generation.

    Returns:
        str: The output generated by the LLM.
    """
    # Define the system prompt for the hypothesizer
    system_prompt = """
You are a threat hunting hypothesis generator. Based on the provided research report 
about a threat actor/technique and any available local context, generate threat 
hunting hypotheses.

## Requirements:
Generate up to 10 threat hunting hypotheses that are:
- Specific: Include concrete technique names, tool names, protocols, target systems, or file patterns
- Testable: Can be proven or disproven through data analysis
- Achievable: Could realistically be investigated with common security tools and logs
- Relevant: Based on the techniques and behaviors described in the research report
- Behavioral: Describe what adversaries ARE DOING, not what detection might show

## Critical Constraints - Hypothesis Structure:

### DO:
- State what adversaries/attackers/threat actors "may be," "are," or "might be" DOING
- Describe observable adversary actions (process execution, file creation, network traffic, authentication attempts)
- Include 3-5 specific details per hypothesis (technique names, tool names, protocols, system types, indicators)
- Focus on 1-2 related behaviors per hypothesis
- Use clear, concise sentences (generally under 35 words)
- Use precise technical terminology (process names, protocol names, specific techniques)

### DO NOT:
- Use detection-focused language: "could indicate," "might suggest," "may reveal," "evidence of"
- Describe investigation activities: "hunt for," "search for," "cross-reference," "systematic review"
- Include time windows or time boundaries (e.g., "in the last 30 days," "during off-hours")
- Specify data sources or log types (e.g., "Sysmon EventID 1," "Windows Event 4688")
- Mention detection products/platforms (e.g., "Splunk," "Zeek," "CrowdStrike," "QRadar")
- Use vague security terms: "suspicious activity," "anomalous behavior," "unusual patterns," "various methods"
- Number or label the hypotheses
- Include explanatory or introductory text

### System References:
- Use generic descriptions (e.g., "domain controllers," "web servers," "endpoints")
- Exception: Specific software names are allowed when the threat targets particular products 
  (e.g., "Exchange 2019," "Apache Log4j," "Confluence")

## Each Hypothesis Must Be:
1. **Independent**: Not dependent on or overlapping with other hypotheses
2. **Behavioral**: Describes adversary actions, not detection outcomes
3. **Observable**: Focuses on activities that leave evidence
4. **Platform-agnostic**: No mention of specific detection tools
5. **Grammatically clear**: One straightforward sentence

## Output Format:
- Return ONLY the hypotheses, one per line
- No introductory text, explanations, or conclusions
- No numbering or labeling
- If you cannot generate any valid hypotheses, respond only with: "No hypotheses could be generated"

## Examples of Good Hypotheses:

Threat actors may be using PowerShell Empire to establish persistence through scheduled tasks on domain-joined Windows endpoints
Attackers may be exploiting unpatched Log4j vulnerabilities in internet-facing Java applications to execute remote commands
Adversaries may be performing reconnaissance by executing abnormal LDAP queries against domain controllers to enumerate privileged accounts
Threat actors may be exfiltrating sensitive data through DNS tunneling using encoded queries to external resolvers
Attackers may be leveraging WMI for lateral movement between workstations by executing remote commands via DCOM
Adversaries may be dumping LSASS process memory using built-in Windows utilities such as rundll32.exe or comsvcs.dll to harvest credentials
Threat actors may be establishing encrypted C2 channels over HTTPS to cloud storage services for command execution and data staging

## Examples of Bad Hypotheses (DO NOT generate hypotheses like these):

Threat actors may be active in the last 30 days using PowerShell
[WRONG: Includes time window]

Evidence of PowerShell Empire in EDR logs could indicate persistence mechanisms
[WRONG: Detection-focused language ("could indicate") and mentions specific tool (EDR)]

Check Cisco ASA firewall logs for suspicious traffic to known C2 servers
[WRONG: Specifies data source and describes investigation activity]

Adversaries might be present somewhere in the network doing suspicious things
[WRONG: Too vague, no specific behaviors, uses "suspicious"]

Use Splunk to search for base64 encoded commands in Windows Event Logs
[WRONG: Mentions detection platform and describes hunting method]

Based on the provided report, here are ten hypotheses:
[WRONG: Introductory text, not a hypothesis]

Hunt for signs of credential dumping using Mimikatz on critical servers
[WRONG: Describes hunting task, not adversary behavior]

Unusual spikes in authentication failures might suggest brute force attacks
[WRONG: Detection-focused language ("might suggest") and vague term ("unusual")]

Cross-referencing Sysmon Event 1 with known malware hashes may uncover malicious process execution
[WRONG: Describes investigation methodology, mentions specific log source]

Threat actors could be leveraging various techniques for lateral movement across different systems
[WRONG: Too vague with "various techniques" and "different systems"]

## Quality Checklist (Internal - Do Not Output):
Before generating each hypothesis, verify:
- [ ] States what adversaries ARE DOING (not what detection shows)
- [ ] Includes 3-5 specific technical details
- [ ] Uses precise terminology (no "suspicious," "unusual," "various")
- [ ] Describes observable activities that leave evidence
- [ ] No detection products, log sources, or investigation methods mentioned
- [ ] Clear sentence structure under 35 words
- [ ] Focuses on 1-2 related behaviors
    """

    messages = [
        SystemMessage(content=system_prompt),
        UserMessage(
            content=f"Here is the research document:\n{research_document}\n",
            source="user",
        ),
        UserMessage(content=f"Here is the user's input: {user_input}\n", source="user"),
        UserMessage(
            content=f"Here is the local data document:\n{local_data_document}\n",
            source="user",
        ),
        UserMessage(
            content=f"Additional local context: {local_context}\n", source="user"
        ),
    ]

    hypothesizer_agent_client = await get_model_client(agent_name="hypothesizer_agent")

    # Call the LLM using the configured provider client
    try:
        result = await hypothesizer_agent_client.create(messages)  # Await the async method
        # Access the content from the CreateResult object
        return str(
            result.content
        )  # Use the correct attribute to access the generated content
    except Exception as e:
        print(f"Error while generating hypotheses: {e}")
        return "An error occurred while generating hypotheses."


def main():
    # Set up argument parser
    parser = argparse.ArgumentParser(
        description="Given a threat hunting technique dossier, generate potential hypotheses for the hunter."
    )
    parser.add_argument("-e", "--environment", help="Path to specific .env file to use")
    parser.add_argument(
        "-r",
        "--research",
        help="Path to the research document (markdown file)",
        required=True,
    )
    parser.add_argument(
        "-u",
        "--user_input",
        help="User input for hypothesis generation",
        required=False,
        default="",
    )
    parser.add_argument(
        "-l",
        "--local-data",
        help="Path to the local data document (markdown file)",
        required=False,
        default=None,
    )
    parser.add_argument(
        "-c",
        "--local_context",
        help="Additional local context to consider",
        required=False,
        default=None,
    )

    args = parser.parse_args()

    # Load environment variables
    if args.environment:
        # Use the specified .env file
        dotenv_path = args.environment
        if not os.path.exists(dotenv_path):
            print(f"Error: Specified environment file '{dotenv_path}' not found")
            exit(1)
        load_dotenv(dotenv_path)
    else:
        # Search for .env file
        dotenv_path = find_dotenv_file()
        if dotenv_path:
            load_dotenv(dotenv_path)
        else:
            print("Warning: No .env file found in current or parent directories")

    # Read the contents of the research document
    try:
        with open(args.research, "r", encoding="utf-8") as file:
            research_data = file.read()
    except FileNotFoundError:
        print(f"Error: Research document '{args.research}' not found")
        exit(1)
    except Exception as e:
        print(f"Error reading research document: {e}")
        exit(1)

    # Read the contents of the local data document if provided
    local_data = None
    if args.local_data:
        try:
            with open(args.local_data, "r", encoding="utf-8") as file:
                local_data = file.read()
        except FileNotFoundError:
            print(f"Error: Local data document '{args.local_data}' not found")
            exit(1)
        except Exception as e:
            print(f"Error reading local data document: {e}")
            exit(1)

    # Read the contents of the local context if provided
    local_context = None
    if args.local_context:
        try:
            with open(args.local_context, "r", encoding="utf-8") as file:
                local_context = file.read()
        except FileNotFoundError:
            print(f"Error: Local context file '{args.local_context}' not found")
            exit(1)
        except Exception as e:
            print(f"Error reading local context: {e}")
            exit(1)

    # Run the hypothesizer asynchronously
    hypotheses = asyncio.run(
        hypothesizer(
            user_input=args.user_input,
            research_document=research_data,
            local_data_document=local_data or "",
            local_context=local_context or "",
        )
    )
    print(hypotheses)


if __name__ == "__main__":
    main()
