#!/usr/bin/env python3
# Copyright (c) 2025 Cisco Systems, Inc. and its affiliates
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
#
# SPDX-License-Identifier: MIT


import os
import argparse
from dotenv import load_dotenv
import asyncio

from autogen_core.models import UserMessage, SystemMessage

from ..utils import find_dotenv_file
from ..utils.llm_factory import get_model_client


async def hypothesizer(
    user_input: str, research_document: str, local_context: str
) -> str:
    """
    Hypothesizer agent that combines user input, a markdown document, and its own prompt
    to generate output using the configured LLM provider.

    Args:
        user_input (str): A string provided by the user.
        research_document (str): A longer string containing a complete markdown document.
        local_context (str): Additional context that may be relevant to the hypothesis generation.

    Returns:
        str: The output generated by the LLM.
    """
    # Define the system prompt for the hypothesizer
    system_prompt = """
You are a threat hunting hypothesis generator. Based on the provided research report 
about a threat actor/technique and any available local context, generate threat 
hunting hypotheses.

## Requirements:
Generate up to 10 threat hunting hypotheses that are:
- Specific: Clearly define the threat actor behavior, technique, or vulnerability
- Measurable: Can be proven or disproven through data analysis
- Achievable: Could realistically be investigated with common security tools and logs
- Relevant: Based on the techniques and behaviors described in the research report

## Critical Constraints:
- Each hypothesis must be completely independent of the others (as much as feasible)
- Do NOT include time windows or time boundaries
- Do NOT specify data sources, log types, or analysis methods. You may include general 
  references (e.g., "network traffic", "system logs", "authentication logs", "EDR logs") but not specific
  data sources (e.g., "Sysmon event code 1", "Zeek HTTP logs")
- Do NOT number or label the hypotheses
- Focus on WHAT might be happening, not HOW to detect it
- Use generic system descriptions (e.g., "mail servers") unless the threat is specific to 
  particular software (e.g., "Exchange 2019")

## Output Format:
- Return ONLY the hypotheses, one per line
- No introductory text, explanations, or conclusions (e.g., do not begin with text like "Based on the 
  provided report and local context, here are ten hypotheses:", "Here are some hypotheses:", etc.)
- If you cannot generate any valid hypotheses, respond only with: "No hypotheses could be generated"

## Examples of Good Hypotheses:
Threat actors may be using PowerShell Empire to establish persistence on Windows endpoints through scheduled tasks
Attackers may be exploiting unpatched Log4j vulnerabilities in internet-facing applications for initial access
Adversaries may be performing reconnaissance through abnormal LDAP queries against domain controllers
Threat actors may be exfiltrating data through DNS tunneling from database servers

## Examples of Bad Hypotheses (DO NOT generate hypotheses like these):
Threat actors may be active in the last 30 days using PowerShell [includes time window]
Check Cisco ASA firewall logs for suspicious traffic to known C2 servers [specifies data source]
Adversaries might be present somewhere in the network [too vague]
Use Splunk to search for base64 encoded commands [specifies tool/method]
Based on the provided report and local context, here are ten hypotheses: [this is explanatory or introductory text not a hypothesis]
4. An unusual spike in failed login attempts from unknown IP addresses might indicate a DDoS attack. [hypothesis is numbered]
Hunt for signs of a data exfiltration attempt using PowerShell Empire. [specifies a task not a hypothesis]
    """

    messages = [
        SystemMessage(content=system_prompt),
        UserMessage(
            content=f"Here is the research document:\n{research_document}\n",
            source="user",
        ),
        UserMessage(content=f"Here is the user's input: {user_input}\n", source="user"),
        UserMessage(
            content=f"Additional local context: {local_context}\n", source="user"
        ),
    ]

    hypothesizer_agent_client = await get_model_client(agent_name="hypothesizer_agent")

    # Call the LLM using the configured provider client
    try:
        result = await hypothesizer_agent_client.create(messages)  # Await the async method
        # Access the content from the CreateResult object
        return str(
            result.content
        )  # Use the correct attribute to access the generated content
    except Exception as e:
        print(f"Error while generating hypotheses: {e}")
        return "An error occurred while generating hypotheses."


def main():
    # Set up argument parser
    parser = argparse.ArgumentParser(
        description="Given a threat hunting technique dossier, generate potential hypotheses for the hunter."
    )
    parser.add_argument("-e", "--environment", help="Path to specific .env file to use")
    parser.add_argument(
        "-r",
        "--research",
        help="Path to the research document (markdown file)",
        required=True,
    )
    parser.add_argument(
        "-u",
        "--user_input",
        help="User input for hypothesis generation",
        required=False,
        default="",
    )
    parser.add_argument(
        "-c",
        "--local_context",
        help="Additional local context to consider",
        required=False,
        default=None,
    )

    args = parser.parse_args()

    # Load environment variables
    if args.environment:
        # Use the specified .env file
        dotenv_path = args.environment
        if not os.path.exists(dotenv_path):
            print(f"Error: Specified environment file '{dotenv_path}' not found")
            exit(1)
        load_dotenv(dotenv_path)
    else:
        # Search for .env file
        dotenv_path = find_dotenv_file()
        if dotenv_path:
            load_dotenv(dotenv_path)
        else:
            print("Warning: No .env file found in current or parent directories")

    # Read the contents of the research document
    try:
        with open(args.research, "r", encoding="utf-8") as file:
            research_data = file.read()
    except FileNotFoundError:
        print(f"Error: Research document '{args.research}' not found")
        exit(1)
    except Exception as e:
        print(f"Error reading research document: {e}")
        exit(1)

    # Read the contents of the local context if provided
    local_context = None
    if args.local_context:
        try:
            with open(args.local_context, "r", encoding="utf-8") as file:
                local_context = file.read()
        except FileNotFoundError:
            print(f"Error: Local context file '{args.local_context}' not found")
            exit(1)
        except Exception as e:
            print(f"Error reading local context: {e}")
            exit(1)

    # Run the hypothesizer asynchronously
    hypotheses = asyncio.run(
        hypothesizer(
            user_input=args.user_input,
            research_document=research_data,
            local_context=local_context,
        )
    )
    print(hypotheses)


if __name__ == "__main__":
    main()
