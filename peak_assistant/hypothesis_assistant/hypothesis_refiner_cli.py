#!/usr/bin/env python3
# Copyright (c) 2025 Cisco Systems, Inc. and its affiliates
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
#
# SPDX-License-Identifier: MIT


import os
import sys
import argparse
from typing import List
from dotenv import load_dotenv
import asyncio

from autogen_agentchat.messages import TextMessage
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.conditions import TextMentionTermination
from autogen_agentchat.teams import RoundRobinGroupChat
from autogen_agentchat.ui import Console
from autogen_agentchat.base import TaskResult

from ..utils import find_dotenv_file
from ..utils.llm_factory import get_model_client
from ..utils.agent_callbacks import (
    preprocess_messages_logging,
    postprocess_messages_logging,
)


async def refiner(
    hypothesis: str,
    local_context: str,
    research_document: str,
    verbose: bool = False,
    previous_run: list = list(),
    msg_preprocess_callback=None,
    msg_preprocess_kwargs=None,
    msg_postprocess_callback=None,
    msg_postprocess_kwargs=None,
) -> TaskResult:
    """
    Threat hunting hypothesis refiner agent that combines user input, a markdown document, and its own prompt
    to generate output using the configured LLM provider.

    Args:
        hypothesis (str): A string provided by the user containing a threat hunting hypothesis.
        user_input (str): A string provided by the user containing additional context or information.
        research_document (str): A longer string containing a complete markdown document.

    Returns:
        str: The output generated by the LLM.
    """
    refiner_system_prompt = """
You are a threat hunting hypothesis advisor. Your job is to help the user improve
their existing threat hunting hypothesis into its best form. Based on the provided 
hypothesis, research report about a threat actor or attack technique, any 
available local context, and feedback about how to improve the hypothesis, generate an 
improved version of the hypothesis.

## Requirements:
The improved hypothesis must be:
- Specific: Clearly define the threat actor behavior, technique, or vulnerability
- Measurable: Can be proven or disproven through data analysis
- Achievable: Could realistically be investigated with common security tools and logs
- Relevant: Based on the techniques and behaviors described in the research report

## Critical Constraints:
- Do NOT include time windows or time boundaries
- Do NOT specify data sources, log types, or analysis methods. You may include general 
  references (e.g., "network traffic", "system logs", "authentication logs", "EDR logs") but not specific
  data sources (e.g., "Sysmon event code 1", "Zeek HTTP logs")
- Do NOT number or label the hypotheses
- Focus on WHAT might be happening, not HOW to detect it
- Use generic system descriptions (e.g., "mail servers") unless the threat is specific to 
  particular software (e.g., "Exchange 2019")

## Output Format:
- Return ONLY the hypothesis
- No introductory text, explanations, or conclusions (e.g., do not begin with text like "Based on the 
  provided report and local context, here are ten hypotheses:", "Here are some hypotheses:", etc.)

## Examples of Good Hypotheses:
Threat actors may be using PowerShell Empire to establish persistence on Windows endpoints through scheduled tasks
Attackers may be exploiting unpatched Log4j vulnerabilities in internet-facing applications for initial access
Adversaries may be performing reconnaissance through abnormal LDAP queries against domain controllers
Threat actors may be exfiltrating data through DNS tunneling from database servers

Threat actors may be active in the last 30 days using PowerShell [includes time window]
Check Cisco ASA firewall logs for suspicious traffic to known C2 servers [specifies data source]
Adversaries might be present somewhere in the network [too vague]
Use Splunk to search for base64 encoded commands [specifies tool/method]
Based on the provided report and local context, here are ten hypotheses: [this is explanatory or introductory text not a hypothesis]
4. An unusual spike in failed login attempts from unknown IP addresses might indicate a DDoS attack. [hypothesis is numbered]
Hunt for signs of a data exfiltration attempt using PowerShell Empire. [specifies a task not a hypothesis]
Refined hypothesis: LSASS process memory on Windows systems is being accessed without proper authorization, indicating potential theft of authentication credentials, leading to unauthorized access and data exfiltration. [Begins with a "Refined hypothesis:" label, no details on how LSASS might be being accessed that can be tested]
    """

    critic_system_prompt = """
You are an expert in cybersecurity threat hunting. Your job is to help the user refine 
their existing threat hunting hypothesis into it's best form. You do this by providing feedback
and suggestions for improvement to their existing hypothesis.

You will be provided with the existing hypothesis (use the most recent version), a research 
document, and any additional guidelines, feedback or context provided by the user. Your job 
is to evaluate the provided hypothesis according to the following requirements and provide 
concise feedback on how to improve it. 

If the hypothesis meets the requirements, reply only with "YYY-HYPOTHESIS-ACCEPTED-YYY".
Do not include any additional commentary, notes, or other text.

If the hypothesis does NOT meet the requirements, state the specific issues with the hypothesis
and provide bullet-point feedback on how to improve it. Do not attempt to refine the hypothesis yourself,
just provide feedback. The refiner agent will use this feedback to refine the hypothesis. The format of your
output in this case should be:

----- begin sample output -----
FEEDBACK:
- Feedback 1
- Feedback 2
- Feedback 3
...
- Feedback N
----- end sample output -----

## Requirements:
The hypothesis must be:
- Specific: Clearly define the threat actor behavior, technique, or vulnerability
- Measurable: Can be proven or disproven through data analysis
- Achievable: Could realistically be investigated with common security tools and logs
- Relevant: Based on the techniques and behaviors described in the research report

## Critical Constraints:
- Do NOT include time windows or time boundaries
- Do NOT specify data sources, log types, or analysis methods. You may include general 
  references (e.g., "network traffic", "system logs", "authentication logs", "EDR logs") but not specific
  data sources (e.g., "Sysmon event code 1", "Zeek HTTP logs")
- Do NOT number or label the hypotheses
- Focus on WHAT might be happening, not HOW to detect it
- Use generic system descriptions (e.g., "mail servers") unless the threat is specific to 
  particular software (e.g., "Exchange 2019")

## Examples of Good Hypotheses:
Threat actors may be using PowerShell Empire to establish persistence on Windows endpoints through scheduled tasks
Attackers may be exploiting unpatched Log4j vulnerabilities in internet-facing applications for initial access
Adversaries may be performing reconnaissance through abnormal LDAP queries against domain controllers
Threat actors may be exfiltrating data through DNS tunneling from database servers

## Examples of Bad Hypotheses (DO NOT generate hypotheses like these):
Threat actors may be active in the last 30 days using PowerShell [includes time window]
Check Cisco ASA firewall logs for suspicious traffic to known C2 servers [specifies data source]
Adversaries might be present somewhere in the network [too vague]
Use Splunk to search for base64 encoded commands [specifies tool/method]
Based on the provided report and local context, here are ten hypotheses: [this is explanatory or introductory text not a hypothesis]
4. An unusual spike in failed login attempts from unknown IP addresses might indicate a DDoS attack. [hypothesis is numbered]
Hunt for signs of a data exfiltration attempt using PowerShell Empire. [specifies a task not a hypothesis]
Refined hypothesis: LSASS process memory on Windows systems is being accessed without proper authorization, indicating potential theft of authentication credentials, leading to unauthorized access and data exfiltration. [Begins with a "Refined hypothesis:" label, no details on how LSASS might be being accessed that can be tested]
    """

    # Get client for refiner agent (used by both refiner and critic)
    hypothesis_refiner_client = await get_model_client(agent_name="hypothesis-refiner")
    hypothesis_refiner_critic_client = await get_model_client(agent_name="hypothesis-refiner-critic")

    # Create the primary agent.
    refiner_agent = AssistantAgent(
        "refiner", model_client=hypothesis_refiner_client, system_message=refiner_system_prompt
    )

    # Create the critic agent.
    critic_agent = AssistantAgent(
        "critic", model_client=hypothesis_refiner_critic_client, system_message=critic_system_prompt
    )

    # Define a termination condition that stops the task if the critic approves.
    text_termination = TextMentionTermination("YYY-HYPOTHESIS-ACCEPTED-YYY")

    # Create a team with the primary and critic agents.
    team = RoundRobinGroupChat(
        [critic_agent, refiner_agent], termination_condition=text_termination
    )

    # Always add these, no matter if it's the first run or a subsequent one
    messages = [
        TextMessage(
            content=f"Here is the user's hypothesis: {hypothesis}\n", source="user"
        ),
        TextMessage(
            content=f"Here is the research document:\n{research_document}\n",
            source="user",
        ),
        TextMessage(
            content=f"Additional local context: {local_context}\n", source="user"
        ),
    ]

    # If we have messages from a previous run, add them so we can continue the research
    if previous_run:
        messages = messages + previous_run

    # Preprocess the messages
    if msg_preprocess_callback:
        messages = msg_preprocess_callback(
            msgs=messages, **(msg_preprocess_kwargs or {})
        )

    try:
        # Run the team asynchronously
        if verbose:
            result = await Console(team.run_stream(task=messages), output_stats=True)
        else:
            result = await team.run(task=messages)

        # Postprocess the result
        if msg_postprocess_callback:
            result = msg_postprocess_callback(
                result=result, **(msg_postprocess_kwargs or {})
            )

        # Access the content from the CreateResult object
        return result  # Use the correct attribute to access the generated content
    except Exception as e:
        print(f"Error while refining hypotheses: {e}")
        return TaskResult(
            messages=[
                TextMessage(
                    content=f"Error while refining hypotheses: {e}",
                    source="system",
                )
            ]
        )


def main() -> None:
    # Set up argument parser
    parser = argparse.ArgumentParser(
        description="Given a threat hunting technique dossier, generate potential hypotheses for the hunter."
    )
    parser.add_argument("-e", "--environment", help="Path to specific .env file to use")
    parser.add_argument(
        "-y", "--hypothesis", help="The hypothesis to be refined", required=True
    )
    parser.add_argument(
        "-r",
        "--research",
        help="Path to the research document (markdown file)",
        required=True,
    )
    parser.add_argument(
        "-c",
        "--local_context",
        help="Additional local context to consider",
        required=False,
        default=None,
    )
    parser.add_argument(
        "-v",
        "--verbose",
        action="store_true",
        help="Enable verbose output",
        default=False,
    )
    parser.add_argument(
        "-a",
        "--automated",
        action="store_true",
        help="Enable automated mode",
        default=False,
    )

    # Parse the arguments
    args = parser.parse_args()

    # Enforce verbose behavior based on the automated flag
    if not args.automated:
        # Force verbose to True if not in automated mode
        args.verbose = True

    # Load environment variables
    if args.environment:
        # Use the specified .env file
        dotenv_path = args.environment
        if not os.path.exists(dotenv_path):
            print(f"Error: Specified environment file '{dotenv_path}' not found")
            exit(1)
        load_dotenv(dotenv_path)
    else:
        # Search for .env file
        dotenv_path = find_dotenv_file()
        if dotenv_path:
            load_dotenv(dotenv_path)
        else:
            print("Warning: No .env file found in current or parent directories")

    # Read the contents of the research document
    try:
        with open(args.research, "r", encoding="utf-8") as file:
            research_data = file.read()
    except FileNotFoundError:
        print(f"Error: Research document '{args.research}' not found")
        exit(1)
    except Exception as e:
        print(f"Error reading research document: {e}")
        exit(1)

    # Read the contents of the local context if provided
    local_context = None
    if args.local_context:
        try:
            with open(args.local_context, "r", encoding="utf-8") as file:
                local_context = file.read()
        except FileNotFoundError:
            print(f"Error: Local context file '{args.local_context}' not found")
            exit(1)
        except Exception as e:
            print(f"Error reading local context: {e}")
            exit(1)

    messages: List[TextMessage] = list()
    current_hypothesis = args.hypothesis
    while True:
        # Run the hypothesizer asynchronously
        response = asyncio.run(
            refiner(
                hypothesis=current_hypothesis,
                local_context=local_context or "",
                research_document=research_data,
                verbose=args.verbose,
                previous_run=messages,
                msg_preprocess_callback=preprocess_messages_logging,
                msg_preprocess_kwargs={"agent_id": "hypothesis-refiner"},
                msg_postprocess_callback=postprocess_messages_logging,
                msg_postprocess_kwargs={"agent_id": "hypothesis-refiner"},
            )
        )

        # Find the final message from the "critic" agent using next() and a generator expression
        refined_hypothesis_message = next(
            (
                getattr(message, "content")
                for message in reversed(response.messages)
                if hasattr(message, "content") and message.source == "critic"
            ),
            "something went wrong",  # Default value if no "critic" message is found
        )

        # Remove the trailing "YYY-HYPOTHESIS-ACCEPTED-YYY" string
        current_hypothesis = refined_hypothesis_message.replace(
            "YYY-HYPOTHESIS-ACCEPTED-YYY", ""
        ).strip()

        # Print the refined hypothesis and ask for user feedback
        print(f"Hypothesis:\n\n{current_hypothesis}")

        if not args.automated:
            feedback = input(
                "Please provide your feedback on the refined hypothesis (or press Enter to approve it): "
            )

            if feedback.strip():
                # If feedback is provided, add it to the messages and loop back to the refiner
                messages.append(
                    TextMessage(content=f"User feedback: {feedback}\n", source="user")
                )
            else:
                break
        else:
            if "YYY-HYPOTHESIS-ACCEPTED-YYY" in refined_hypothesis_message:
                print(
                    "Automated mode: Hypothesis refinement completed.", file=sys.stderr
                )
                break


if __name__ == "__main__":
    main()
